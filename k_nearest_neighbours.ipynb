{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets,utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knn():\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.classification_grid = None\n",
    "        self.k = 0\n",
    "        \n",
    "    def get_predicted_class(self, reference_point, datapoints, k):\n",
    "        \"\"\"\n",
    "        Calculates the distance to all datapoints, finds the k nearest neighbours and predicts the \n",
    "        classmemberships based on neighbours.\n",
    "        \"\"\"\n",
    "        #calculate distance to all datapoints\n",
    "        distances_neighbours = []\n",
    "        for n in range(len(datapoints)):\n",
    "            distances_neighbours.append([np.linalg.norm(reference_point - datapoints[n]), n])\n",
    "        distances_neighbours.sort()\n",
    "        \n",
    "        #Get knn\n",
    "        knn_index = np.array(distances_neighbours)[:k,1]\n",
    "        knn_labels = [self.y_train[int(index)] for index in knn_index]\n",
    "\n",
    "        # Predict class for reference point\n",
    "        classes = {np.sum(np.sum(np.array(knn_labels)==0)):0, \n",
    "                   np.sum(np.sum(np.array(knn_labels)==1)):1, \n",
    "                   np.sum(np.sum(np.array(knn_labels)==2)):2}\n",
    "        most_common = max(classes.keys())\n",
    "\n",
    "        return classes[most_common]\n",
    "\n",
    "        \n",
    "    def fit(self, k, dim_0=0, dim_1=1):\n",
    "        \"\"\"\n",
    "        Generates a contourplot that shows the decisionboundarys for a given k.\n",
    "        \"\"\"\n",
    "        \n",
    "        X1_range = np.linspace(min(self.X_train[:,dim_0])-1, max(self.X_train[:,dim_0])+1,50)\n",
    "        X2_range = np.flip(np.linspace(min(self.X_train[:,dim_1])-1, max(self.X_train[:,dim_1])+1,50))\n",
    "        distances_to_nn = []\n",
    "        classification = []\n",
    "        for x2,i in zip(X2_range, range(len(X2_range))):\n",
    "            classification.append([])\n",
    "            for x1,j in zip(X1_range, range(len(X1_range))):\n",
    "                \n",
    "                classification[i].append(self.get_predicted_class([x1, x2], self.X_train[:,[dim_0,dim_1]], k=k))\n",
    "        classification = np.array(classification)\n",
    "        self.classification_grid = classification\n",
    "        \n",
    "        x_grid, y_grid = np.meshgrid(X1_range, X2_range) \n",
    "        \n",
    "        fig,ax = plt.subplots()\n",
    "\n",
    "        ax.contourf(x_grid, y_grid ,classification)\n",
    "        color = ['r','g','b']\n",
    "        plt.scatter(self.X_train[:,dim_0], self.X_train[:,dim_1], c=self.y_train, edgecolors='white')\n",
    "\n",
    "    def predict(self, X_test, y_test, k):\n",
    "        \"\"\"\n",
    "        Predicts the class belongings for X_test and compares it to y_test.\n",
    "        Returns the predicted class belongings and the accuracy for the predictions.\n",
    "        \"\"\"\n",
    "        y_predict = []\n",
    "        \n",
    "        for x in X_test:\n",
    "            y_predict.append(self.get_predicted_class(x, self.X_train, k=k))\n",
    "            \n",
    "        y_predict = np.array(y_predict)\n",
    "        accuracy = np.sum(y_predict==y_test) / len(y_test)\n",
    "    \n",
    "        return np.transpose(y_predict), accuracy\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "#iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_X, iris_y = utils.shuffle(iris['data'], iris['target'])\n",
    "\n",
    "#split into test and train data\n",
    "x_train, y_train = iris_X[0:130], iris_y[0:130]\n",
    "x_test, y_test = iris_X[130:], iris_y[130:]\n",
    "\n",
    "# Runn knn classification on iris\n",
    "k = 10\n",
    "knn_iris = knn(x_train, y_train)\n",
    "knn_iris.fit(k, dim_0=0, dim_1=1)\n",
    "\n",
    "knn_iris.predict(x_test, y_test, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load wine dataser\n",
    "wine = datasets.load_wine()\n",
    "wine_X, wine_y = utils.shuffle(wine['data'], wine['target'])\n",
    "\n",
    "#split into test and train data\n",
    "x_train, y_train = wine_X[0:160], wine_y[0:160]\n",
    "x_test, y_test = wine_X[160:], wine_y[160:]\n",
    "\n",
    "# Runn knn classification on wine\n",
    "k = 8\n",
    "knn_wine = knn(x_train, y_train)\n",
    "knn_wine.fit(k, dim_0=0, dim_1=1)\n",
    "\n",
    "knn_wine.predict(x_test, y_test, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
